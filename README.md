# Image Segmentation with U-Net

## **Overview**
This project demonstrates image segmentation using the **U-Net architecture**. Image segmentation involves labeling each pixel of an image to classify objects or regions, enabling detailed object recognition.

## **Dataset**
- A **synthetic dataset** was generated for this project.
- Each image has dimensions of **128x128 pixels** with three color channels (RGB).
- Corresponding segmentation masks are binary images indicating object regions.

## **Model**
### U-Net Architecture
- **U-Net** is a convolutional neural network (CNN) designed for image segmentation tasks.
- The network consists of:
  - **Encoder (Downsampling Path)**: Extracts features using convolutional layers and max-pooling.
  - **Bottleneck**: Contains the most compressed representation of the input.
  - **Decoder (Upsampling Path)**: Reconstructs the segmentation mask by upsampling and concatenating with encoder features.
- Final output is a **1-channel binary mask** with pixel values ranging from 0 to 1.

## **Steps in the Project**
1. **Data Generation**:
   - Synthetic images and masks were generated for training and testing.
   - Dataset split: **80% training** and **20% testing**.

2. **Model Design**:
   - The U-Net model was implemented using TensorFlow/Keras.
   - Added `Dropout` layers for regularization and to prevent overfitting.

3. **Training**:
   - Optimizer: **Adam**
   - Loss function: **Binary Crossentropy**
   - Metrics: **Accuracy**
   - Trained for **10 epochs** with a batch size of 16.

4. **Evaluation**:
   - The model achieved an accuracy of **50.01%** on the test set.
   - Results are impacted due to synthetic data; performance can be improved with real-world datasets.

5. **Visualization**:
   - Predicted segmentation masks were compared with true masks to evaluate the model visually.


### Visual Results
The following visualizations were produced:
- **Original Image**
- **True Mask** (Ground Truth)
- **Predicted Mask** (Generated by the U-Net model)
